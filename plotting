
#install.packages("FSA")
#install.packages("gridExtra")
library(gridExtra)
library(FSA)
library(ggpubr)
library(ggplot2)


fhmeansgen1 = c(mean(Fhmeans.5),mean(Fhmeans.10), mean(Fhmeans.25), mean(Fhmeans.50), mean(Fhmeans.100), mean(Fhmeans.250), mean(Fhmeans.500))
fhmeansgen2 = c(mean(fh150means.5), mean(fh150means.10), mean(fh150means.50), mean(fh150means.100), mean(fh150means.250), mean(fh150means.500))

#plot FH for 50 generations.
fit.5 = locfit(~Fhmeans.5, alpha=0.9)
fit.10 =locfit(~Fhmeans.10, alpha=0.9)
fit.25 =locfit(~Fhmeans.25, alpha=0.9)
fit.50 = locfit(~Fhmeans.50, alpha=0.9)
fit.100 = locfit(~Fhmeans.100, alpha=0.9)
fit.250 = locfit(~Fhmeans.250, alpha=0.9)
fit.500 = locfit(~Fhmeans.500, alpha=0.9)

#locfit fits the line better. #all the same bc immediately before + after a bottle neck it is difficult to distinguish. probably also sizes of pop  
#plot means of fH
par(mfrow=c(1,1))
plot(2,3, xpd=FALSE)
legend("center", legend=c("5", "10", "25", "50", "100", "250", "500"), col=colours, inset=0.5, cex=0.9, fill=colours, bty="n", title="Bottleneck Size", horiz=TRUE, xpd=FALSE, ncol=14)



layout(matrix(c(1, 2, 3, 4), nrow=2, byrow=TRUE))


par(mar=rep(4,4))
plot(NULL, xlim=c(0.3, 1), ylim=c(0,20), xlab="Mean Fh: 50", ylab="Density")
lines(fit.5, col="deeppink", lwd=2)
lines(fit.10, col="blueviolet", lwd=2)
lines(fit.25, col="forestgreen", lwd=2)
lines(fit.50, col="darkorange1", lwd=2)
lines(fit.100, col="deepskyblue", lwd=2)
lines(fit.250, col="gray48", lwd=2)
lines(fit.500, col="black", lwd=2)
colours=c("deeppink", "blueviolet", "forestgreen", "darkorange1", "deepskyblue", "gray48", "black")
# legend("top", legend=c("5", "10", "25", "50", "100", "250", "500"), col=colours, cex=1, fill=colours, bty="n", title="Bottleneck Size", horiz=FALSE)
abline(v=mean(fhmeansgen1), lty=4)

#plot FH for 150 generations
plot(NULL, xlim=c(0.3, 1), ylim=c(0,20), xlab="Mean Fh: 150", ylab="Density")
lines(locfit(~fh150means.5, alpha=0.9), lwd=2, col="deeppink")
lines(locfit(~fh150means.10, alpha=0.9), col="blueviolet" , lwd=2)
lines(locfit(~fh150means.25, alpha=0.9) , col="forestgreen", lwd=2)
lines(locfit(~fh150means.50, alpha=0.9), col="darkorange1", lwd=2)
lines(locfit(~fh150means.100, alpha=0.9), col="deepskyblue", lwd=2)
lines(locfit(~fh150means.250, alpha=0.9), col="gray48", lwd=2)
lines(locfit(~fh150means.500, alpha=0.9), col="black", lwd=2)
abline(v=mean(fhmeansgen2), lty=4)



#maybe zoom in?
plot(NULL, xlim=c(0.85, 1), ylim=c(0,20), xlab="Mean Fh: 50", ylab="Density")
lines(fit.5, col="deeppink", lwd=2)
lines(fit.10, col="blueviolet", lwd=2)
lines(fit.25, col="forestgreen", lwd=2)
lines(fit.50, col="darkorange1", lwd=2)
lines(fit.100, col="deepskyblue", lwd=2)
lines(fit.250, col="gray48", lwd=2)
lines(fit.500, col="black", lwd=2)
colours=c("deeppink", "blueviolet", "forestgreen", "darkorange1", "deepskyblue", "gray48", "black")
# legend("top", legend=c("5", "10", "25", "50", "100", "250", "500"), col=colours, cex=1, fill=colours, bty="n", title="Bottleneck Size", horiz=FALSE)
abline(v=mean(fhmeansgen1), lty=4)
#plot FH for 150 generations
plot(NULL, xlim=c(0.85, 1), ylim=c(0,20), xlab="Mean Fh: 150", ylab="Density")
lines(locfit(~fh150means.5, alpha=0.9), lwd=2, col="deeppink")
lines(locfit(~fh150means.10, alpha=0.9), col="blueviolet" , lwd=2)
lines(locfit(~fh150means.25, alpha=0.9) , col="forestgreen", lwd=2)
lines(locfit(~fh150means.50, alpha=0.9), col="darkorange1", lwd=2)
lines(locfit(~fh150means.100, alpha=0.9), col="deepskyblue", lwd=2)
lines(locfit(~fh150means.250, alpha=0.9), col="gray48", lwd=2)
lines(locfit(~fh150means.500, alpha=0.9), col="black", lwd=2)
abline(v=mean(fhmeansgen2), lty=4)



#density is due to smoothing + weighting of how the curve was made, what you say is the higher densities is where the majority of your data is. 
#have to have a histogram to see  how many have a particular value
#just describe by saying majority of values are like this; figure represents distribtuion for each model of FH, 1000 sims. if you have lines for the means + medians for each sim, you can say mean is bla +- bla, 
#density is a complex thing to explain bc of the fitting etc. 
#legend: distribution of Fh values for each founder pop model. each curve corresponds to 1000 points. 
#hist with freq=FALSE, looks like density one, ogical; if TRUE, the histogram graphic is a representation of frequencies, the counts component of the result; if FALSE, probability densities, component density, are plotted (so that the histogram has a total area of one). Defaults to TRUE if and only if breaks are equidistant (and probability is not specified)
#rememeber to say 500 is constant pop
#put growth rate formula in (exponential); say you wanted exponential growth 
#drawing of models, then link to the table. 
#put that its time1, t0 etc _ put the growth rate etc. 

#could plot mean + median for both if you want
#do both in a multiple pannel thing (par mfrow)
#try 150 generations for victorian times for FH to see what happens + can compare both? 
#rad data is fragments and would be more complex to simulate those 
#need explain effective pop size, expected homozygosity  + observed homozygosity; what the formula is doing + what it means if you have 1 value or the other. 
#table with parameters + can put reference for where you got it from 
#remember to say you just used minor allle frequency - put the formulas down. (+ refs)
#these graphs are the malaysian. 
#plot the medians of FH

fhmeans1box = list(Fhmeans.5, Fhmeans.10, Fhmeans.25, Fhmeans.50, Fhmeans.100, Fhmeans.250, Fhmeans.500)
fhmeansgen2box = list(fh150means.5, fh150means.10, fh150means.50, fh150means.100, fh150means.250, fh150means.500)
#Plot Fh boxplot for 50 gen
par(mfrow=c(1,2))
boxplot(fhmeans1box, ylim= c(0.3, 1), xaxt = "n", xlab='Founder size', ylab="Mean Fh over 50 generations")
axis(1, at=1:7, labels=c("5","10","25","50","100", "250", "500"))
boxplot(fhmeansgen2box, ylim= c(0.3, 1), xaxt = "n", xlab='Founder size', ylab=" Mean Fh Over 150 Generations")
axis(1, at=1:7, labels=c("5","10","25","50","100", "250", "500"))


par(mfrow=c(1,1))

fhmeansA= c(Fhmeans.5, Fhmeans.10, Fhmeans.25, Fhmeans.50, Fhmeans.100, Fhmeans.250, Fhmeans.500)
fhmeansB = c(fh150means.5, fh150means.10, fh150means.25, fh150means.50, fh150means.100, fh150means.250, fh150means.500)

mean(fhmeansA)
mean(fhmeansB)
x.factor = as.factor(c(rep(5,1000), rep(10,1000),rep(25,1000), rep(50,1000), rep(100,1000), rep(250,1000), rep(500,1000)))

###ANALYSIS

#anova needs equal variances + normality of residuals
#homoscedasticity = levenes; needs to be insignificant
#QQ plot is of residuals and is normal if all the points are more or less on the line of best fit



# analysis ----------------------------------------------------------------


#Assume the dependent variable is y and the treatment codes are in the variable x. There are two ways to do a one-way ANOVA, using different functions. In each case I will output the results to an R object and then, with the function anova, ask for the ANOVA table to be extracted from that object. Method one: 
#analysis for 50 generations
AFH.data = data.frame(fhmeansA, x.factor) #make datafram where x is factor and y is numeric
str(AFH.data)
AFHaov.out = aov(fhmeansA~x.factor, data=AFH.data)
plot(AFHaov.out,2) #homosecdasticity
hist(resid(AFHaov.out)) #normal?
library(car)
leveneTest(fhmeansA~x.factor, data=AFH.data) #if insig; equal variances
summary.lm(AFHaov.out) #if sig, run the tukey. 
#FH.AOV = TukeyHSD (FHaov.out)
#if not normal, run kruskal: 
kruskal.test(fhmeansA~x.factor, data=AFH.data)
#quote as Kruskal-Wallis Ï‡2 = 1.64 d.f. = 2, P = 0.442.
dunnTest(fhmeansA, x.factor)

#analysis for 150 generations 
BFH.data = data.frame(fhmeansB, x.factor) #make datafram where x is factor and y is numeric
BFHaov.out = aov(fhmeansB~x.factor, data=BFH.data)
plot(BFHaov.out,2) #homosecdasticity
hist(resid(BFHaov.out)) #normal?
library(car)
leveneTest(fhmeansB~x.factor, data=BFH.data) #0.605 = insig; equal variances
summary.lm(BFHaov.out) #if sig, run the tukey. 
#FH.AOV = TukeyHSD (FHaov.out)
#if not normal, run kruskal: 
kruskal.test(fhmeansB~x.factor, data=BFH.data)
dunnTest(fhmeansB, x.factor)


yfh5 = c(Fhmeans.5, fh150means.5)
t.factor5 = as.factor(c(rep(1,1000), rep(2,1000)))
ttest5 = data.frame(yfh5, t.factor5)
t.test(yfh5~t.factor5)
#t tess require normaility: histogram + normailty of residuals
leveneTest(yfh5~t.factor5, data=ttest5) #sig means non-equal 
wilcox.test(yfh5~t.factor5)
#result: W = 635420, p-value < 2.2e-16

yfh10 = c(Fhmeans.10, fh150means.10)
t.factor10 = as.factor(c(rep(1,1000), rep(2,1000)))
ttest10 = data.frame(yfh10, t.factor10)
wilcox.test(yfh10~t.factor10)
#result: W = 631570, p-value < 2.2e-16

yfh25 = c(Fhmeans.10, fh150means.10)
t.factor25 = as.factor(c(rep(1,1000), rep(2,1000)))
ttest25 = data.frame(yfh25, t.factor25)
wilcox.test(yfh25~t.factor25)
#result: W = 631570, p-value < 2.2e-16


yfh50 = c(Fhmeans.50, fh150means.50)
t.factor50 = as.factor(c(rep(1,1000), rep(2,1000)))
ttest50 = data.frame(yfh50, t.factor50)
wilcox.test(yfh50~t.factor50)
#result: W = 665270, p-value < 2.2e-16

yfh100 = c(Fhmeans.100, fh150means.100)
t.factor100 = as.factor(c(rep(1,1000), rep(2,1000)))
ttest100 = data.frame(yfh100, t.factor100)
wilcox.test(yfh100~t.factor100)
#W = 673670, p-value < 2.2e-16

yfh250 = c(Fhmeans.250, fh150means.250)
t.factor250 = as.factor(c(rep(1,1000), rep(2,1000)))
ttest250 = data.frame(yfh250, t.factor250)
wilcox.test(yfh250~t.factor250)
# W = 701140, p-value < 2.2e-16

yfh500 = c(Fhmeans.500, fh150means.500)
t.factor500 = as.factor(c(rep(1,1000), rep(2,1000)))
ttest500 = data.frame(yfh500, t.factor500)
wilcox.test(yfh500~t.factor500)

#W = 706380, p-value < 2.2e-16


